{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D \n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from google.colab import files\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_zip = '/content/rockpaperscissors.zip' \n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/content/tempDataset')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/content/tempDataset/rockpaperscissors/'\n",
    "train_dir = os.path.join(base_dir, 'rps-cv-images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Split = 0.4\n",
    "batch_Size = 32\n",
    "target_Size = 150\n",
    "mode = 'categorical'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    validation_split = val_Split \n",
    ")\n",
    "\n",
    "validation_data = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = val_Split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_data.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (target_Size, target_Size),\n",
    "    batch_size = batch_Size, \n",
    "    class_mode = mode, \n",
    "    subset = 'training' \n",
    ")\n",
    "\n",
    "validation_generator = validation_data.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (target_Size, target_Size),\n",
    "    batch_size = batch_Size,\n",
    "    class_mode = mode,\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding = 'Same', activation = 'relu', input_shape = (target_Size, target_Size, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2))) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2))) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding = 'Same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2))) \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback\n",
    "auto_reduction_LR = ReduceLROnPlateau(\n",
    "    monitor = 'val_accuracy',\n",
    "    patience = 2, #if after 2 epoch not improve reduce LR by factor\n",
    "    verbose = 1,\n",
    "    factor = 0.5,\n",
    "    min_lr = 0.000003\n",
    ")\n",
    "\n",
    "auto_stop_learn = EarlyStopping(\n",
    "    monitor = 'val_accuracy',\n",
    "    min_delta = 0,\n",
    "    patience = 4,\n",
    "    verbose = 1,\n",
    "    mode = 'auto' \n",
    ")\n",
    "\n",
    "#Compile\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy'] \n",
    ")\n",
    "\n",
    "#Fit\n",
    "History = model.fit(\n",
    "    train_generator,\n",
    "    epochs = 7,\n",
    "    validation_data = validation_generator,\n",
    "    callbacks = [auto_reduction_LR, auto_stop_learn]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_plot(History):\n",
    "  plt.plot(History.history['loss'])\n",
    "  plt.plot(History.history['val_loss'])\n",
    "  plt.title('Model Loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend(['train', 'test'])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(model):\n",
    "  validation_generator = train_data.flow_from_directory(\n",
    "          train_dir, \n",
    "          target_size = (target_Size,target_Size), \n",
    "          batch_size= batch_Size, \n",
    "          class_mode = mode,\n",
    "          shuffle = False,\n",
    "          subset = 'validation'\n",
    "  )\n",
    "\n",
    "  num_test_samples = len(validation_generator.filenames)\n",
    "\n",
    "  Y_test = model.predict(validation_generator, num_test_samples // batch_Size+1)\n",
    "  y_test = np.argmax(Y_test, axis = 1)\n",
    "\n",
    "  print('\\nConfusion Matrix\\n')\n",
    "  print(confusion_matrix(validation_generator.classes, y_test))\n",
    "\n",
    "  print('\\nAccuracy Score: {:.2f}\\n'.format(accuracy_score(validation_generator.classes, y_test)))\n",
    "\n",
    "  print('Micro Precision: {:2f}'.format(precision_score(validation_generator.classes, y_test, average='micro')))\n",
    "  print('Micro Recall: {:.2f}'.format(recall_score(validation_generator.classes, y_test, average='micro')))\n",
    "  print('Micro F1-score: {:.2f}\\n'.format(f1_score(validation_generator.classes, y_test, average='micro')))\n",
    "\n",
    "  print('Macro Precision: {:2f}'.format(precision_score(validation_generator.classes, y_test, average='macro')))\n",
    "  print('Macro Recall: {:.2f}'.format(recall_score(validation_generator.classes, y_test, average='macro')))\n",
    "  print('Macro F1-score: {:.2f}\\n'.format(f1_score(validation_generator.classes, y_test, average='macro')))\n",
    "\n",
    "  print('Weighted Precision: {:.2f}'.format(precision_score(validation_generator.classes, y_test, average='weighted')))\n",
    "  print('Weighted Recall: {:.2f}'.format(recall_score(validation_generator.classes, y_test, average='weighted')))\n",
    "  print('Weighted F1-score: {:.2f}'.format(f1_score(validation_generator.classes, y_test, average='weighted')))\n",
    "\n",
    "  print('\\nClassification Report\\n')\n",
    "  target = ['Rock', 'Paper', 'Scissors']\n",
    "  print(classification_report(validation_generator.classes, y_test, target_names=target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_plot(History)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image():\n",
    "  uploaded = files.upload()\n",
    "\n",
    "  for fn in uploaded.keys():\n",
    "    #predict img\n",
    "    path = fn\n",
    "    img = image.load_img(path, target_size = (target_Size, target_Size))\n",
    "\n",
    "    imgplot = plt.imshow(img)\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "\n",
    "    img_toNPArr = np.asarray(images)\n",
    "    img_toNPArr *= (1./255)\n",
    "    img_in = tf.reshape(img_toNPArr, shape = [1, target_Size, target_Size, 3])\n",
    "\n",
    "    probability = round((sorted(model.predict(img_in)[0])[2])*100, 2)\n",
    "    predict_class = np.argmax(model.predict(img_in))\n",
    "\n",
    "    if predict_class == 0:\n",
    "        predict_label = 'Paper'\n",
    "    elif predict_class == 1:\n",
    "        predict_label = 'Rock'\n",
    "    else:\n",
    "        predict_label = 'Scissor'\n",
    "    \n",
    "    print('\\n')\n",
    "    plt.show()\n",
    "    print(\"\\nImage prediction result: \", predict_label)\n",
    "    print(\"Probability: \", probability, \"%\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3a30b30deef41df88df190d46993bfd96e0a37053d2e575a57d0d2e9c4fc826d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
